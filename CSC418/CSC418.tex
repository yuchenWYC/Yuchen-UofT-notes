\documentclass[11pt]{article}
% Libraries.

\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{esint}
\usepackage[margin=2cm]{geometry}
%\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{perpage}
\usepackage[dvipsnames, pdftex]{xcolor}
\usepackage{float}
\usepackage{xargs}
\usepackage{/Users/raina/Desktop/uoft-notes/raina}
\usepackage[
	colorinlistoftodos,
	prependcaption,
	textsize=tiny
]{todonotes}
\usepackage{minted}

\numberwithin{equation}{section}

% Property settings.
\MakePerPage{footnote}
\pagestyle{headings}

% Attr.
\title{CSC418\\ Lecture Notes}
\author{Yuchen Wang}
\date{\today}

\begin{document}
    \maketitle
    \tableofcontents
    \newpage
\section{Raster Images}
\begin{enumerate}
	\item Raster displays show images as rectangular arrays of pixels.
	\item Images should be arrays of floating-point numbers, with either one (for \tb{grayscale}, or black and white images), or three (for \tb{RGB} color images) 32-bit floating point numbers stored per pixel.
\end{enumerate}

\paragraph{Images as functions}
Grayscale: $I(x, y): \real^2 \rightarrow \real$\\
RGB: $I(x, y): \real^2 \rightarrow \real^3$\\



\paragraph{Bayer filters}
A \tb{Bayer filter} is a color filter array for arranging RGB color filters on a square grid of photosensors. The information is stored as a seemingly 1-channel image, but with an understood convention for interpreting each pixel as the red, green or blue intensity value with a fixed pattern.
\paragraph{Demosaic algorithm}
To demosaic an image, we would like to create a full rgb image without downsampling the image resolution. For each pixel
\begin{enumerate}
	\item We'll use the exact color sample when it's available;
	\item We average available neighbors (in all 8 directions) to fill in missing colors.
\end{enumerate}

	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p25}
	\caption{a: Bayer filters; bcd: Demosaic algorithm}
	\end{figure}


\paragraph{Image storage on the computer}
To reduce the storage requirement, most image formats allow for some kind of compression, either \ti{lossless} or \ti{lossy}.
\begin{itemize}
	\item \tb{jpeg}: Lossy, compresses image blocks based on thresholds in the human visual system, works well for natural images.
	\item \tb{tiff}: Losslessly compressed 8- or 16-bit RGB, or hold binary images.
	\item \tb{ppm}: Lossless, uncompressed, most often used for 8-bit RGB images. Color intensities are represented as an integer between 0 and 255.
	\item \tb{png}: Lossless, with a good set of open source management tools. \blue{can store rgba images}
\end{itemize}
In our assignment we use the convention that the red value of pixel in the top-left corner comes first, then its green value, then its blue value, and then the rgb values of its neighbor to the right and so on across the row of pixels, and then moving to the next row down the columns of rows.

\paragraph{RGB images}

\paragraph{HSV images}
Another useful representation is store the hue, saturation, and value of a color. This "hsv" representation also has 3-channels: typically, the hue or h channel is stored in degrees (i.e., on a periodic scale) in the range $[0^\circ, 360^\circ]$ and the saturation s and value v are given as absolute values in $[0,1]$.

\paragraph{HSV/RGB conversion}
\tb{Desaturation}: Given a \texttt{factor}, for each pixel,
\begin{enumerate}
	\item Convert RGB values to HSV
	\item Let $s \gets (1-factor) * s$
	\item Convert HSV back to RGB
\end{enumerate}
\tb{Hue shifting}:
\tb{Desaturation}: Given a \texttt{shift}, for each pixel,
\begin{enumerate}
	\item Convert RGB values to HSV
	\item Let $h \gets (h + shift) \text{ mod } 360$
	\item Convert HSV back to RGB
\end{enumerate}

\paragraph{Grayscale images}
Take a weighted average of RGB values given higher priority to green:
\begin{equation}
	i = 0.2126r + 0.7152g + 0.0722b
\end{equation}


\paragraph{Alpha masking}
It is often useful to store a value $\alpha$ representing \under{how opaque each pixel is}. \\
When we store rgb + $\alpha$ image as a 4-channel rgba image. Just like rgb images, rgba images are 3D arrays unrolled into a linear array in memory.

\section{Ray Casting}
\subsection{General Ray Casting Algorithm}
\begin{framed}
\begin{minted}{C}
for each pixel in the image {
	Generate a ray
	for each object in the scene {
		if (Intersect ray with object){
			Set pixel color
		}
	}
}
\end{minted}
\end{framed}
\subsection{Basics}
\notation
$\vs$: the scene\\
$\ve$: the camera\\
$\vd$: the viewing direction
$p(t)$: point along ray
\paragraph{Parametric equation for ray}
A ray emanating from a point $\ve \in \real^3$ in a direction $\vd \in \real^3$ can be parameterized by a single number $t \in [0, \infty)$. Changing the value of $t$ picks a different point along the ray. The parametric function for a ray is
\begin{align}
	p(t) &= \ve + t(\vs - \ve) \\
	&= \ve + t\vd
\end{align}
where $p(0) = \ve$ and $p(1) = \vs$.\\
If $0 < t_1 < t_2$, then $p(t_1)$ is closer to the eye than $p(t_2)$.\\
Also, if $t < 0$, then $p(t)$ is ``behind" the eye.

\paragraph{Camera space}
\begin{align}
	\vw &= -\frac{View}{||View||} \\
	\vu &= View \times Up \\
	\vv &= \vw \times \vu
\end{align}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p26}
	\end{figure}

\subsection{Orthographic/perspective projection}
The view that is produced is determined by the choice of projection direction and image plane.
\begin{enumerate}
	\item \tb{Orthographic projection}: The image plane is perpendicular to the view direction
	\item \tb{Oblique projection}: The image plane is \under{not} perpendicular to the view direction
	\item \tb{Perspective projection}: Project alone lines that pass through a single \ti{view point}, rather than along parallel lines
\end{enumerate}

\paragraph{Orthographic views}
$l$ and $r$ are the positions of the left and right edges of the image, as measured from e along the $\vu$ direction; and b and t are the positions of the bottom and top edges of the image, as measured from $\ve$ along the $\vv$ direction. Usually $l < 0 < r$ and $b < 0 < t$. \\
To fit an image with $n_x \times n_y$ pixels into a rectangle of size $(r-l) \times (t-b)$, the pixels are spaced a distance $(r - l)/n_x$ apart horizontally and $(t-b)/n_y$ apart vertically, with a half-pixel space around the edge to center the pixel grid within the image rectangle.
\begin{align}
	u &= l + (r - l)(i+0.5)/n_x \\
	v &= b + (t - b)(j+0.5)/n_y
\end{align}
where $(u, v)$ are the coordinates of the pixel's position on the image plane, measured with respect to the origin $\ve$ and the basis $\{\vu, \vv\}$.\\
The procedure for generating orthographic viewing rays is then:
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p27}
	\end{figure}

\paragraph{Perspective views}
The image plane is some distance $d$ (\ti{image plane distance}) in front of $\ve$. The resulting procedure is
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p29}
	\end{figure}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p28}
	\end{figure}
	
\subsection{Ray-Object Intersection}
\subsubsection{Plane}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p30}
	\end{figure}
	

\subsubsection{Sphere}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p31}
	\end{figure}

\begin{align}
	intersect &= \ve + \vt * \vd\\
	\vn &= (intersect - \vc).normalized()
\end{align}
	

\subsubsection{Triangle}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p32}
	\end{figure}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p33}
	\end{figure}
	
\begin{align}
	\vn &= [(\vb - \va) \times (\vc - \va)].normalized()
\end{align}



\section{Ray Tracing}
\subsection{General Ray Tracing Algorithm}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p34}
	\includegraphics[scale=0.3]{p35}
	\end{figure}
\subsection{Image-order vs Object-order rendering}
\paragraph{Image-order rendering}
Each pixel is considered in turn, and for each pixel all the objects that influence it are found and the pixel value is computed.\\
\blue{Simpler to get working, more flexible in the effects that can be produced, usually takes much more execution time to produce a comparable image.}

\paragraph{Object-order rendering}
Each object is considered in turn, and for each object all the pixels that it influences are found and updated.

\subsection{Two types of lights}
\paragraph{Directional Light}
Direction of light does not depend on the position of the object. Light is very far away.

\paragraph{Point Light}
Direction of light depends on position of object relative to light.

\subsection{Shading \label{Shading}}
\notation
The important variables in light reflection are \red{unit vectors}\\
\under{Light direction} $\vl$: a unit vector pointing toward the light source;\\
\under{View direction} $\vv$: a unit vector pointing toward the eye or camera;\\
\under{Surface normal} $\vn$: a unit vector perpendicular to the surface at the point where reflection is taking place.

\subsubsection{Lambertian Shading}
An observation by Lambert in the 18th century: the amount of energy from a light source that falls on an area of surface depends on the angle of the surface to the light.
\definition[Lambertian shading model]
The vector $\vl$ is computed by subtracting the intersection point of the ray and the surface from the light source position.\\
The pixel color
$$L = k_dI\max(0, \vn \cdot \vl)$$
where $k_d$ is the \ti{diffuse coefficient}, or the surface color; and $I$ is the intensity of the light source.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{p1}
	\caption{Geometry for Lambertian shading}
\end{figure}
\remark
Because $\vn$ and $\vl$ are unit vectors, we can use $\vn \cdot \vl$ as a convenient shorthand for $\cos \theta$. This equation applies separately to the three color channels.
\remark
Lambertian shading is \ti{view independent:} the color of a surface does not depend on the direction from which you look. Therefore it does not produce any highlights and leads to a very matte, chalky appearance.

\subsubsection{Blinn-Phong Shading}
A very simple and widely used model for specular highlights by Phong (1975) and J.F.Blinn (1976).
\paragraph{Idea}
Produce reflection that is at its brightest when $\vv$ and $\vl$ are symmetrically positioned across the surface normal, which is when mirror reflection would occur; reflection then decreases smoothly as the vectors move away from a mirror configuration.\\
Compare the half vector $\vh$ with $\vn$: if $\vh$ is near the surface normal, the specular component should be bright and vice versa.
\definition[Blinn-Phong shading model]
\begin{align*}
	\vh &= \frac{\vv + \vl}{\norm{\vv + \vl}} \\
	L &= k_d I \max(0, \vn \cdot \vl) + k_s I \max(0, \vn \cdot \vh)^p
\end{align*}
where $k_s$ is the \ti{specular coefficient}, or the specular color of the surface, and $p > 1$.

\subsubsection{Ambient Shading}
A heuristic to avoid black shadows is to add a constant component to the shading model, one whose contribution to the pixel color depends only on the \blue{object hit}, with no dependence on the \blue{surface geometry} at all, as if surfaces were illuminated by ambient light that comes equally from everywhere.
\definition[simple shading model / Blinn-Phong model with ambient shading]
$$L = k_a I_a + k_d I \max (0, \vn \cdot \vl) + k_s I \max (0, \vn \cdot \vh)^p$$
where $k_a$ is the surface's ambient coefficient or ``ambient color", and $I_a$ is the ambient light intensity.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p4}
\end{figure}


\subsubsection{Multiple Point Lights}
\property[superposition]
The effect by more than one light source is simply the sum of the effects of the light sources individually.
\definition[extended simple shading model]
$$L = k_a I_a + \sum_{i=1}^N[k_dI_i\max(0, \vn \cdot \vl_i) + k_sI_i \max(0, \vn \cdot \vh_i)^p]$$
where $I_i, \vl_i$ and $\vh_i$ are the intensity, direction, and half vector of the $i$-th light source.

\subsection{A Ray-Tracing Program}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p2}
\end{figure}

\subsection{Shadows}
Recall from \ref{Shading} that light comes from direction $\vl$. If we imagine ourselves at a point $\vp$ on a surface being shaded, the point is in shadow if we ``look" in direction $\vl$ and see an object. If there are no objects, then the light is not blocked.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.73]{p3}
\end{figure}

\remark
The usual adjustment to avoid the problem of intersecting $\vp$ with the surface that generates it is to make the shadow ray check for $t \in [\epsilon, \infty)$ where $\epsilon$ is some small positive constant.

\remark
The code above assumes that $\vd$ and $\vl$ are not necessarily unit vectors. 

\subsection{Ideal Specular Reflection}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p5}
	\caption{When looking into a perfect mirror, the viewer looking in direction $\vd$ will see whatever the viewer ``below" the surface would see in direction $\vr$}
\end{figure}
$$\vr = \vd - 2(\vd \cdot \vn)\vn$$
In the real world, a surface may reflect some colors more efficiently than others, so it shifts the colors of the objects it reflects (i.e. some energy is lost when the light reflects from the surface). \\
We implement the reflection by a recursive call of \ti{raycolor}:
\begin{framed}
\begin{minted}{C}
	color c = c + km * raycolor(p + sr, epsilon, max_t);
\end{minted}
\end{framed}
\noindent where $k_m$ is the specular RGB color, $p$ is the intersection of the viewing ray and the surface, $s \in [\epsilon, max\_t)$ for the same reason as we did with shadow rays: we don't want the reflection ray to hit the object that generates it.\\
To make sure that the recursive call will terminate, we need to add a maximum recursion depth.


\section{Bounding Volume Hierachy}
\subsection{Two types of subdivisions}
\tb{Object-based subdivision}:
\begin{itemize}
	\item AABB Trees
\end{itemize}
\tb{Spatial subdivision}:
\begin{itemize}
	\item Uniform Spatial Subdivision
	\item Axis-Aligned Spatial Subdivision
\end{itemize}


\subsection{Bounding Boxes}
\definition
	We first consider a 2D ray whose direction vector has positive $x$ and $y$ components. The 2D bounding box is defined by two horizontal and two vertical lines:
	$$x = x_{\min}$$
	$$x = x_{\max}$$
	$$y = y_{\min}$$
	$$y = y_{\max}$$
	The points bounded by these lines can be described in interval notation:
	$$(x,y) \in [x_{\min}, x_{\max}] \times [y_{\min}, y_{\max}]$$
	The intersection test can be phrased in terms of these intervals. First, we compute the ray parameter where the ray hits the line $x = x_{\min}$:
	$$t_{xmin} = \frac{x_{\min} - x_e}{x_d}$$
	We then make similar computations for $t_{xmax}, t_{ymin}$, and $t_{ymax}$. The ray hits the box if and only if the intervals $[t_{xmin}, t_{xmax}]$ and $[t_{ymin}, t_{ymax}]$ overlap.
	
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{p6}
	\caption{The algorithm pseudocode.}
	\end{figure}
	
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.45]{p7}
	\end{figure}
\paragraph{Ray-AABB Intersection}
If $\max(t_{xmin}, t_{ymin}, y_{zmin}) < \min(t_{xmax}, t_{ymax}, y_{zmax})$, then the ray intersects with the box.

\paragraph{Issue 1}
The first thing we must address is the case when $x_d$ or $y_d$ is negative. If $x_d$ is negative, then the ray will hit $x_{\max}$ before it hits $x_{\min}$. Thus the code for computing $t_{xmin}$ and $t_{xmax}$ expands to:
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{p8}
	\end{figure}
A similar code expansion must be made for the $y$ cases.
	
\paragraph{Issue 2}
A major concern is that horizontal and vertical rays have a zero value for $y_d$ and $x_d$, respectively. This will cause divide by zero which may be a problem. We define the \tb{rules for divide by zero}: \\
For any positive real number $a$,
$$+a / 0 = +\infty$$
$$-a / 0 = -\infty$$
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{p9}
	\caption{The new code segment.}
	\end{figure}

\subsection{Axis-Aligned Bounding Boxes Tree (AABB Tree)}
In our assignment, we will build a binary tree. Conducting queries on the tree will be reminiscent of searching for values in a \ti{binary search tree}.

	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{p36}
	\end{figure}

\noindent \tb{Basic idea}: Place an axis-aligned 3D bounding box around all the objects. Since testing for intersection with the box is not free, rays that hit the bounding box will be more expensive to compute than in a brute force search, but rays that miss the box are cheaper. Such bounding boxes can be made hierarchical by partitioning the set of objects in a box and placing a box around each partition.\\
\remark
Each object belongs to one of two sibling nodes, whereas a point in space may be inside both sibling nodes.\\
\remark[pros and cons]
As follows:
\begin{itemize}
	\item pros: \blue{Operations (e.g. growing the bounding box, testing ray intersection or determining closest-point distances with an axis-aligned bounding box) usually reduce to trivial per-component arithmetic. This means the code is simple to write/debug and also inexpensive to evaluate.}
	\item cons: \blue{In general, AABBs will not tightly enclose a set of objects.}
\end{itemize}
\paragraph{Ray intersection algorithm}
The ray intersection algorithm is essentially performing a \red{depth first search}.
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p11}
	\end{figure}
\paragraph{Distance query algorithm}
In this algorithm, we are interested in which box in the AABB tree is the closest to a fixed point.
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p10}
	\end{figure}
\remark[pros and cons of DFS]
As follows:
\begin{itemize}
	\item pros: \blue{The search usually doesn't have to visit the entire tree because most boxes are not hit by the given ray. In this way, many search paths are quickly aborted.}
	\item cons: \blue{Every box has some closest point to our query. A naive depth-first search could end up searching over every box before finding the one with the smallest query.}
	\item BFS is a much better structure since it makes use of a priority queue to explore the current best looking path in our tree.
\end{itemize}
\remark
\tb{Tree construction complexity:} $\mc{O}(n\log n)$\\
\tb{Tree traversal complexity:} $\mc{O}(n)$ (worst case) \\
\tb{Brute force complexity:} $\mc{O}(n)$




\subsection{Object-Oriented Bounding Box (OOBB)}
Find directions of maximum variance using PCA.


\subsection{Uniform Spatial Subdivision}
In spatial division, each point in space belongs to exactly one node, whereas objects may belong to many nodes.\\
The scene is partitioned into axis-aligned boxes. These boxes are all the same size, although they are not necessarily cubes. The ray traverses these boxes. When an object is hit, the traversal ends.

	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{p12}
	\end{figure}

\noindent This traversal is done in an increment fashion. We need to find the index $(i, j)$ of the first cell hit by the ray $\ve + t\vd$. Then we need to traverse the cells in an appropriate order. 

\subsection{Axis-Aligned Binary Space Partitioning (BSP Trees)}
We can also partition space in a hierarchical data structure such as a \ti{binary space partitioning tree} (BSP tree). It's common to use axis-aligned cutting planes for ray intersection.\\
A node in this structure contains a single cutting plane and a left and right subtree. Each subtree contains all the objects on one side of the cutting plane. Objects that pass through the plane are stored in both subtrees. \red{If we assume the cutting plane is parallel to the $yz$ plane at $x = D$, then the node class is:}
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{p13}
	\end{figure}
The intersection code can then be called recursively in an object-oriented style. The code considers the four cases:

	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{p14}
	\end{figure}
The origin of these rays is a point at parameter $t_0$:
$$\vp = \va + t_0 \vb$$
The four cases are:
\begin{enumerate}
	\item The ray only interacts with the left subtree, and we need not test it for intersection with the cutting plane. It occurs for $x_p < D$ and $x_b < 0$.
	\item The ray is tested against the left subtree, and if there are no hits, it is then tested against the right subtree. We need to find the ray parameter at $x = D$, so we can make sure we only test for intersections within the subtree. This case occurs for $x_p < D$ and $x_b > 0$.
	\item This case is analogous to case 1 and occurs for $x_p > D$ and $x_b > 0$.
	\item This case is analogous to case 2 and occurs for $x_p > D$ and $x_b < 0$.
\end{enumerate}
The resulting traversal code handling these cases in order is:
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{p15}
	\end{figure}

\section{Triangle Meshes}
\paragraph{Motivation} 
\begin{itemize}
	\item Mesh is a basic computer graphics data structure.
	\item Most real-world models are composed of complexes of triangles with shared vertices. These are usually known as \tb{triangle meshes}, and handling them efficiently is crucial to the performance of many graphics programs. 
	\item We'd like to minimize the amount of storage consumed.
	\item Besides basic operations (storing \& drawing), other operations such as \ti{subdivision}, \ti{mesh editing} and \ti{mesh compression}, \under{efficient access to adjacency information} is crucial.
\end{itemize}


\subsection{Mesh Topology}
\property[Manifold meshes]
The topology of a mesh is a \tb{manifold} surface: A surface in which a small neighborhood around any point could be smoothed out into a bit of flat surface.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{p16}
\end{figure}
\paragraph{Verifying the property}
Prevent crashes or infinite loops by checking:
\begin{enumerate}
	\item Every edge is shared by exactly two triangles.	 (as in figure 12.1)
	\item Every vertex has a single, complete loop of triangles around it. (as in figure 12.2)
\end{enumerate}


\property[Manifold with boundary meshes]
Sometimes it's necessary to allow meshes to have boundaries. Such meshes are not manifolds. However, we can relax the requirements of a manifold mesh to those for a \tb{manifold with boundary} without causing problems for most mesh processing algorithms. The relaxed conditions are:
\begin{enumerate}
	\item Every edge is used by either one or two triangles.
	\item Every vertex connects to a single edge-connected set of triangles.
\end{enumerate}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{p17}
\end{figure}
\noindent Figure 12.3 illustrates these conditions. 

\property[orientation]
For a single triangle, we define orientation based on the order in which the vertices are listed: \blue{the front is the side from which the triangle's three vertices are arranged in counterclockwise order.}\\
A connected mesh is \tb{consistently oriented} if its triangles all agree on which side is the front.


\subsection{Indexed Mesh Storage}
\definition[Separate triangles]
Store each triangle as an independent entity.
\begin{framed}
\begin{minted}{C}
Triangle {
	vector3 vertexPosition[3]
}
\end{minted}
\end{framed}

\definition[Indexed Shared-vertex mesh]
This data structure has triangles which \tb{point to} vertices which contain the vertex data:
\begin{framed}
\begin{minted}{C}
Triangle {
	Vertex v[3]
}

Vertex {
	vector3 position
}
\end{minted}
\end{framed}
In implementation, the vertices and triangles are normally stored in arrays:
\begin{framed}
\begin{minted}{C}
IndexedMesh{
	int tInd[nt][3]
	vector3 verts[nv]
}
\end{minted}
\end{framed}
\noindent The index of the $k$th vertex of the $i$th triangle is found in \texttt{tInd[i][k]}, and the position of that vertex is stored in the corresponding row of the \texttt{verts} arary.
	\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{p18}
	\end{figure}
\paragraph{Space requirements}
If our mesh has $n_v$ vertices and $n_t$ triangles, and if we assume that the data for floats, pointers, and ints all require the same storage, the space requirements are as follows:
\begin{itemize}
	\item \tb{Triangle}: Three vectors per triangle, for $9n_t$ units of storage;
	\item \tb{IndexedMesh}: One vector per vertex and three ints per triangle, for $3n_v + 3n_t$ units of storage.
\end{itemize}
Empirically, $n_t \approx 2n_v$.

\subsection{Triangle Strips and Fans}
In applications where even more compactness is desirable, the triangle vertex indices can be expressed more efficiently using \tb{triangle strips} and \tb{triangle fans}.

\definition[Triangle fan]
All the triangles share one common vertex, and the other vertices generate a set of triangles like the vanes of a collapsible fan (Figure 12.9). \blue{The fan in the figure could be specified with the sequence $[0, 1, 2, 3, 4, 5]$: the first vertex establishes the center, and subsequently each pair of adjacent vertices creates a triangle.}
\definition[Triangle strip]
Here, vertices are added alternating top and bottom in a linear strip as shown in Figure 12.10. \blue{The triangle strip in the figure could be specified by the sequence [0 1 2 3 4 5 6 7], and every subsequence of three adjacent vertices creates a triangle.} For consistent orientation, every other triangle needs to have its order reversed. For each new vertex that comes in, the oldest vertex is forgotten and the order of the two remaining vertices is swapped.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p19}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p20}
\end{figure}
\noindent \red{In both strips and fans, $n+2$ vertices suffice to describe $n$ triangles.}

\subsection{Data Structures for Mesh Connectivity}
\subsubsection{The Triangle-Neighbor Structure}
Augmenting the basic shared-vertex mesh with pointers from the triangles to the three neighboring triangles, and a pointer from each vertex to one of the adjacent triangles (it doesn't matter which one)
\begin{framed}
\begin{minted}{C}
Triangle {
	Triangle nbr[3];
	Vertex v[3];
}

Vertex {
	// ... per-vertex data ...
	Triangle t; // any adjacent tri
}
\end{minted}
\end{framed}
\noindent \blue{In the array \texttt{Triangle.nbr}, the $k$th entry points to the neighboring triangle that shares vertices $k$ and $k + 1$.}\\
Implementation:
\begin{framed}
\begin{minted}{C}
Mesh{
	vector3 verts[nv] // per-vertex data 
	int tInd[nt][3]; // vertex indices
	int tNbr[nt][3]; // indices of neighbor triangles
	int vTri[nv]; // index of any adjacent triangle
}
\end{minted}
\end{framed}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p21}
\end{figure}

The idea is to move from triangle to triangle, visiting only the triangles adjacent to the relevant vertex. If triangle t has vertex v as its kth vertex, then the triangle t.nbr[k] is the next triangle around v in the clockwise direction. This observation leads to the following algorithm to traverse all the triangles adjacent to a given vertex:
\begin{framed}
\begin{minted}{C}
TrianglesOfVertex(v) { t = v.t
do {
find i such that (t.v[i] == v) t = t.nbr[i]
} while (t != v.t) }
\end{minted}
\end{framed}
A small refinement to let us find the previous triangle:
\begin{framed}
\begin{minted}{C}
Triangle {
   Edge nbr[3];
   Vertex v[3];
}
Edge { // the i-th edge of triangle t Triangle t;
   int i;  // in {0,1,2}
}
Vertex {
   // ... per-vertex data ...
   Edge e; // any edge leaving vertex
}

\end{minted}
\end{framed}

\begin{framed}
\begin{minted}{C}
TrianglesOfVertex(v) { 
	{t, i} = v.e;
	do {
		{t, i} = t.nbr[i];
		i = (i+1) mod 3;
	} while (t != v.e.t);
}

\end{minted}
\end{framed}

\subsection{The Winged-Edge Structure}
In a winged-edge mesh, each edge stores pointers to the two vertices it connects (the head and tail vertices), the two faces it is part of (the left and right faces), and, most importantly, the next and previous edges in the counterclock- wise traversal of its left and right faces (Figure 12.16). Each vertex and face also stores a pointer to a \under{single, arbitrary edge} that connects to it:
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p21}
\end{figure}

\begin{framed}
\begin{minted}{C}
Edge {
	Edge lprev, lnext, rprev, rnext; 
	Vertex head, tail;
	Face left, right;
}
Face {
	// ... per-face data ...
	Edge e; // any adjacent edge
}
Vertex {
	// ... per-vertex data ... Edge e; // any incident edge
}
\end{minted}
\end{framed}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{p22}
\end{figure}

The search algorithm:
\begin{figure}[H]
%	\centering
	\includegraphics[scale=0.5]{p23}
\end{figure}

\subsection{The Half-Edge Structure}
The winged-edge structure is quite elegant, but it has one remaining awkward- nessâ€”the need to constantly check which way the edge is oriented before moving to the next edge. \\
Solution: Store data for each \tb{half-edge}. There is one half-edge for each of the two triangles that share an edge, and the two half-edges are oriented oppositely, each oriented consistently with its own triangle.\\
\blue{The data normally stored in an edge is split between the two half-edges. Each half-edge points to the face on its side of the edge and to the vertex at its head, and each contains the edge pointers for its face. It also points to its neighbor on the other side of the edge, from which the other half of the information can be found.}
\begin{framed}
\begin{minted}{C}
HEdge {
   HEdge pair, next;
   Vertex v;
   Face f;
}
Face {
	// ... per-face data ...
	HEdge h; // any h-edge of this face
}
Vertex {
	// ... per-vertex data ...
	HEdge h; // any h-edge pointing toward this vertex
}

\end{minted}
\end{framed}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p24}
\end{figure}

The search algorithm:
\begin{framed}
\begin{minted}{C}
EdgesOfVertex(v) { 
	h = v.h;
	do {
		h = h.pair.next;
	} while (h != v.h); 
}

EdgesOfFace(f) { 
	h = f.h;
	do {
		h = h.next;
	} while (h != f.h); 
}
\end{minted}
\end{framed}

The vertex traversal here is clockwise, which is necessary because of omitting the prev pointer from the structure.\\
Because half-edges are generally allocated in pairs (at least in a mesh with no boundaries), many implementations can do away with the pair pointers. For instance, in an implementation based on array indexing (such as shown in Figure 12.18), the array can be arranged so that an even-numbered edge $i$ always pairs with edge $i + 1$ and an odd-numbered edge $j$ always pairs with edge $j-1$.\\
In addition to the simple traversal algorithms shown in this chapter, all three of these mesh topology structures can support "mesh surgery" operations of various sorts, such as splitting or collapsing vertices, swapping edges, adding or removing triangles, etc.
\subsection{Different types of normals}
\paragraph{Per-Face Normals}
The surface will have a \tb{faceted appearance}. This appearance is mathematically correct, but not necessarily desired if we wish to display a smooth looking surface.
\paragraph{Per-Vertex Normals}
Corners of triangles located at the same vertex should share the same normal vector. \tb{Smooth appearance}. A common way to define per-vertex normals is to take a \tb{area-weighted average} of normals from incident faces:
\begin{equation}
	\vn_{v} = \frac{\sum_{f\in N(v)} a_f\vn_{f}}{||\sum_{f\in N(v)} a_f\vn_{f}||}
\end{equation}
where $N(v)$ is the set of faces neighboring the $v$-th vertex, $a_f$ is the area of face $f$, and $\vn_f$ is the normal vector of face $f$.

\paragraph{Per-Corner Normals}
For surfaces with a mixture of smooth-looking parts and creases, it is useful to define normals independently for each triangle corner (as opposed to each mesh vertex). For each corner, we'll again compute an area-weighted average of normals triangles incident on the shared vertex at this corner, but we'll ignore triangle's whose normal is too different from the corner's face's normal:
\begin{equation}
	\vn_{f,c} = \frac{\sum_{g \in N(v)|\vn_{g}\cdot \vn_{f}>\epsilon} a_g\vn_{g}}{||\sum_{g \in N(v)|\vn_{g}\cdot \vn_{f}>\epsilon} a_g\vn_{g}||}
\end{equation}
where $\epsilon$ is the minimum dot  product between two face normals before we declare there is a crease between them.


\subsection{Catmull-Clark subdivision algorithm}
\paragraph{Subdivision Surfaces}
A Recursive refinement of polygonal mesh that results in smooth 	``limit surface".

\paragraph{Catmull-Clark subdivision algorithm}
The first and still popular subdivision scheme.
\begin{enumerate}
	\item Set the face point for each facet to be the average of its vertices.
	\item Add edge points - average of two neighboring face points and edge end points.
	\item Add edges between face points and edge points.
	\item Move each original vertex according to new position given by
	$$\frac{F + 2R + (n-3)P}{n}$$
	where $F$ is average of all $n$ created face points adjacent to $P$ and $R$ is average of all original edge midpoints touching $P$.
	\item Connect up original points to make facets
	\item Repeat
	
\end{enumerate}
\unsure{If texture coordinates is on the test, look up textbook p249}

\section{Shader Pipeline}
\definition[rasterization]
The process of finding all the pixels in an image that are occupied by a geometric primitive is called \tb{rasterization}.

\definition[graphics pipeline]
The sequence of operations that is required, starting with objects and ending by updating pixels in the image, is known as the \tb{graphics pipeline}.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p37}
\end{figure}
\paragraph{Tessellation control shader}
Determines how to subdivide each input patch. The subdivision is determined independently for each triangle and not called recursively.\\
Unlike the vertex or fragment shader, the tessellation control shader has access to attribute information at all of the vertices of a triangle.

\paragraph{Tessellation evaluation shader}
Takes the result of the tessellation that the ``tessellation control shader" has specified. This shader is called once for every vertex output during tessellation. It has access to the attribute information of the original corners and a special variable \texttt{gl\_TessCoord} containing the barycentric coordinates of the current vertex. Using this information, it is possible to interpolate information stored at the original corners onto the current vertex (e.g. the 3D position).

\definition[Bump map]
A \tb{bump map} is a mapping from a surface point to a displacement along the normal direction. Each point $\vp \in \real^3$ on the surface is moved to a new position $\tilde{\vp} \in \real^3$:
\begin{equation}
	\tilde{\vp}(\vp) := \vp + h(\vp)\hat{\vn}(\vp)
\end{equation} 
where $h: \real^3 \rightarrow \real$ is the bump height amount function (could be negative) and $\hat{\vn}(\vp): \real^3 \rightarrow \real^3$ is the mathematically correct normal at $\vp$.
\remark
The idea is that a bump map is a height field: a function that give the local height of the detailed surface above the smooth surface.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p40}
\end{figure}

\definition[Normal map]
A \tb{normal map} is a mapping from a surface point to a unit normal vector.\\
To create a consistent and believable looking normal map, we can first generate a plausible bump map. If our bump height $h$ is a smooth function over the surface, we can compute the perceived normal vector $\tilde{\vn}$ by taking a small finite difference of the 3D position:
\begin{equation}
	\tilde{\vn} = \frac{\partial \vp}{\partial T} \times \frac{\partial \vp}{\partial B} \approx \left( \frac{\tilde{\vp}(\vp + \epsilon T) - \tilde{\vp}(\vp)}{\epsilon} \right) \times  \left( \frac{\tilde{\vp}(\vp + \epsilon B) - \tilde{\vp}(\vp)}{\epsilon} \right)
\end{equation}
where $T, B \in \real^3$ are orthogonal tangent and bi-tangent vectors in the tangent plane at $\vp$ and $\epsilon$ is a small number (e.g. 0.0001). \\
We'll make sure that this approximate perceived normal is unit length by dividing by its length:
\begin{equation}
	\tilde{\vn} \gets \frac{\tilde{\vn}}{||\tilde{\vn}||}
\end{equation}
\remark
Normal mapping is useful in computer graphics because we can drape the appearance of a complex surface on top a low resolution and simple one.\\
\remark
Normal mapping makes the shading normal depend on values read from a texture map.
\remark
It does not change the surface at all, just a shadowing trick that create the illusion of depth detail on the surface of a model.

\paragraph[Perlin noise]
A type of gradient noise used to produce natural appearing textures.
\begin{enumerate}
	\item Grid definition: Define an n-dimensional grid where each point has a random n-dimensional unit-length gradient vector.
	\item Dot product: An n-dimensional candidate point can be viewed as falling into an n-dimensional grid cell. Fetch the $2^n$ closest gradient values, located at the $2^n$ corners of the grid cell. Then for each gradient value, compute a distance vector from each corner node to the candidate point. Then compute the dot product between each pair of gradient vector and distance vector. \blue{This function has a value of 0 at the node and a gradient equal to the precomputed node gradient.}
	\item Interpolation: Performed using a function that has zero first derivative at the $2^n$ grid nodes.
\end{enumerate}
If $n=1$, an example of a function that interpolates between value $a_0$ at grid node 0 and value $a_1$ at grid node 1 is
\begin{equation}
	f(x) = a_0 + smoothstep(x) \cdot (a_1 - a_0)
\end{equation}
for $0 \leq x \leq 1$, where
\begin{equation}
	smoothstep(x) = \begin{cases}
		0 & x\leq 0\\
		3x^2 - 2x^3 & 0\leq x \leq 1\\
		1 & x \geq 1
	\end{cases}
\end{equation}
\definition{Tangent and bitangent vector}
Let $s(x,y,z)$ and $t(x,y,z)$ be differentiable scalar functions defined at all points on a surface $S$. In computer graphics, the functions $s$ and $t$ often represent texture coordinates for a 3-dimensional polygonal model. In this context, the \tb{tangent vector} $T(p_x, p_y, p_z)$ is specifically defined to be the unit vector lying in the tangent plane for which
\begin{equation}
	\grad_T t(p_x, p_y, p_z) = 0, \grad_T s(p_x, p_y, p_z) > 0
\end{equation}
The \tb{bitangent vector} $B(p_x, p_y, p_z)$ is defined to be the unit vector lying in the tangent plane for which

\begin{equation}
	\grad_T s(p_x, p_y, p_z) = 0, \grad_T t(p_x, p_y, p_z) > 0
\end{equation}
\remark
The vectors $T$ and $B$ are not necessarily orthogonal and may not exist for poorly conditioned functions $s$ and $t$.

\subsection{Rasterization}
For each primitive that comes in, the rasterizer has two jobs:
\begin{enumerate}
	\item It enumerates the pixels that are covered by the primitive.
	\item It interpolates values, called attributes, across the primitive.
\end{enumerate}
The output is called \tb{fragments}, one for each pixel covered by the primitive. Each fragment ``lives" at a particular pixel and carries its own set of attribute values.

\subsubsection{Triangle Rasterization}
\definition[Gouraud interpolation]
If the vertices have colors $\vc_0, \vc_1$ and $\vc_2$, the color at a point in the triangle with barycentric coordinates $(\alpha, \beta, \gamma)$ is
\begin{equation}
	\vc = \alpha\vc_0 + \beta \vc_1 + \gamma\vc_2
\end{equation}
\\
We are usually rasterizing triangles that share vertices and edges. To draw them with no holes, we can use the midpoint algorithm to draw the outline of each triangle and then fill in the interior pixels.\\
Pixels are drawn iff their centers are inside the triangle, i.e., the barycentric coordinates of the pixel center are all in the interval $(0,1)$.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p38}\\
	\includegraphics[scale=0.5]{p39}
	\caption{Algorithm for triangle rasterization.}
\end{figure}

\subsection{Operations Before and After Rasterization}
\subsubsection{Vertex-processing stage}
\begin{enumerate}
	\item Incoming vertices are transformed by the modeling, viewing, and projection transformations, mapping them from their original coordinates into screen space.
	\item Other information, such as colors, surface normals, or texture coordinates, is transformed as needed.
\end{enumerate}

\subsubsection{Fragment processing stage}
\begin{enumerate}
	\item 
\end{enumerate}
\subsubsection{Blending stage}
Combines the fragments generated by the primitives that overlapped each pixel to compute the final color. The most common blending approach is to choose the color of the fragment with the smallest depth (closest to the eye).
 
\paragraph{Using a z-buffer for hidden surfaces}
At each pixel, we keep track of the distance to the closest surface that has been drawn so far, and we throw away fragments that are farther away than that distance.\\
The closest distance is stored by allocating an extra value for each pixel, in addition to the rgb values, which is known as the depth, or z-value. The \tb{z-buffer} is the name for the grid of depth values.
\remark
Of course there can be ties in the depth test, in which case the order may well matter.

\section{Kinematics}
Study of motion without consideration of what causes that motion.
\section{Mass-Spring Systems}
\subsection{Bones}
\definition[skeleton]
A \tb{skeleton} is a tree of rigid bones. Each bone in the skeleton is a UI widget for visualizing and controlling a 3D rigid transformation. A common visualization of 3D bone in computer graphics is a long, pointed pyramid shape.
\definition[Canonical bones]
The ``canonical bone" of length $l$ lies along the $x$-axis with its ``tail" at the origin $(0, 0, 0)$, its ``tip" at $(l, 0, 0)$.\\
\tb{Twisting} is rotating about the $x$-axis in the canonical frame.\\
\tb{Bending} is rotating about the $z$-axis in the canonical frame.
\remark
Composing a twist, bend and another twist spans all possible 3D rotations.
We call the three angles composed into a rotation this way, \tb{Euler angles}.
\definition[Rest bones]
For each bone, there is a rigid transformation that places its tail and tip to the desired positions in the model.
\begin{equation}
	\hat{T} = \begin{pmatrix}\hat{R}\hat{\vt}\end{pmatrix} \in \real^{3\times 4}
\end{equation}
where $T$ = transformation, $R$ = rotation and $t$ = translation.
We use the convention that the ``canonical tail" (the origin $(0,0,0)$) is mapped to the ``rest tail" inside the model. This means that the translation part of the matrix $\hat{T}$ is simply the rest tail position $\hat{\vs} \in \real^3$:
\begin{equation}
	\hat{\vs} = \hat{T}\begin{pmatrix}
		0 \\ 0\\ 0 \\ 1
	\end{pmatrix} = \hat{R} \begin{pmatrix}
		0 \\ 0 \\ 0 
	\end{pmatrix} + \hat{\vt}1 = \hat{\vt}
\end{equation}
The bone's rotation is chosen so that the ``canonical tip" maps to the ``rest tip" $\hat{\vd} \in \real^3$:
\begin{equation}
	\hat{\vd} = \hat{T}\begin{pmatrix}
		l \\ 0\\ 0 \\ 1
	\end{pmatrix} = \hat{R} \begin{pmatrix}
		l \\ 0 \\ 0 
	\end{pmatrix} + \hat{\vt}1 = \hat{\vt}
\end{equation}
\blue{Typically the ``rest tail" of a bone is coincident with the ``rest tip" of its parent (if it exists)}
\begin{equation}
	\hat{\vd}_p = \hat{\vs}
\end{equation}
\remark
The \tb{pose} of each bone will be measured relative to the ``rest bone".

\definition[Pose bones]
In general, each rest bone undergoes a rigid transformation $T \in \real^{3\times 4}$, composed of a rotation $R \in \real^{3 \times 4}$ and a translation $\vt \in \real^3$, mapping each of its rest points $\hat{x} \in \real^3$ to its corresponding posed position $\vx \in \real^3$:
\begin{equation}
	\vx = T\hat{\vx}
\end{equation}
\remark
In particular, we would like each bone to rotate about its parent's tip, but this position is determined by the parent's pose transformation $T_p$, which in turn should rotate about the grandparent's tip and so on.

\subsection{Forward Kinematics}
For each bone $i$ in a skeleton, we aggregate relative rotations $\overline{R_i} \in \real^{3\times 3}$ between a bone $i$ and its parent bone $p_i$ in the skeletal tree.\\
For each bone:
\begin{enumerate}
	\item First undo the map from canonical to rest (inverting $\hat{T}_i$);
	\item Then rotate by the relative rotation $\overline{R_i}$;
	\item Then map back to rest (via $\hat{T}_i$);
	\item Continue up the tree recursively applying the parent's relative transformation.
\end{enumerate}
\begin{equation}
	T_i = T_{p_i}\begin{pmatrix}
		\hat{T}_i 
	\end{pmatrix}
\end{equation}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{p41}
\end{figure}

\definition[Linear Blend Skinning]
Skinning is the process of defining how bones are attached to the meshes. In linear blend skinning, each vertex $i$ of the mesh is assigned a weight $w_{i,j}$ for each bone $j$ corresponding to how much it is ``attached" to that bone on a scale of $0\%$ to $100\%$:
\begin{equation}
	\vv_i = \sum_{j=1}^m w_{i,j}T_j\begin{pmatrix}
		\hat{\vv}_i \\ 1
	\end{pmatrix}
\end{equation}


\subsection{Keyframe animation}
To create a long animation, specifying three Euler angles for every bone for every frame manually would be too difficult. The standard way to determine the relative bone transformations for each frame is to interpolate values specified at a small number of "key" times during the animation. 
 \definition[Catmull-Rom interpolation]
 $\theta = \vc(t)$ is a curve in the pose space. A \tb{cubic Hermite spline} is a spline where each piece is a third-degree polynomial specified by its values and first derivatives.
 \todo{incomplete}
 \subsection{Inverse Kinematics}
 \todo{\href{https://github.com/psarahdactyl/computer-graphics-kinematics}{A6}}
 \subsection{Projected Gradient Descent}
 \todo{\href{https://github.com/psarahdactyl/computer-graphics-kinematics}{A6}}
 \subsection{Line Search}
 \todo{\href{https://github.com/psarahdactyl/computer-graphics-kinematics}{A6}}

\section{Mass-Spring Systems}



\section{Computational Fabrication}




\end{document}

